---
layout: ../../layouts/BlogPost.astro
title: "VoxThymio : Contr√¥le Vocal Intelligent du Robot Thymio avec IA"
description: "Syst√®me avanc√© de reconnaissance vocale et compr√©hension s√©mantique pour piloter des robots Thymio par la voix, utilisant Whisper, BERT et ChromaDB."
date: "2025-09-15"
category: "Robotique & IA"
tags: ["Robotique", "NLP", "Speech Recognition", "Whisper", "BERT", "ChromaDB", "Thymio", "Embeddings"]
author: "Esp√©rance AYIWAHOUN"
---

## ü§ñ Introduction

**VoxThymio** est un syst√®me avanc√© de contr√¥le vocal pour robots **Thymio** d√©velopp√© pour **AI4Innov**. Il utilise l'intelligence artificielle pour comprendre et ex√©cuter des commandes en langage naturel, avec un syst√®me d'apprentissage dynamique qui enrichit automatiquement sa base de connaissances.

**üì¶ Code source :** [GitHub - VoxThymio](https://github.com/TitanSage02/Vox-Thymio)

---

## üìã Probl√©matique

### Limitations des Syst√®mes Existants

Les robots √©ducatifs comme Thymio sont traditionnellement programm√©s via :
- **Interfaces graphiques** (Aseba, Blockly) ‚Üí Non intuitif pour d√©butants
- **Code Aseba** ‚Üí Barri√®re technique pour enseignants
- **T√©l√©commande infrarouge** ‚Üí Interactions limit√©es

**Besoin identifi√© :** Un syst√®me de contr√¥le **vocal naturel** qui :
1. Comprend les **variations linguistiques** ("avance", "va tout droit", "va devant")
2. **Apprend dynamiquement** de nouvelles commandes
3. Fonctionne **hors ligne** (sans connexion internet)
4. Offre une **latence faible** (< 2 secondes)

---

## üèóÔ∏è Architecture Technique

### Stack Technologique

| Composant | Technologie | R√¥le |
|-----------|-------------|------|
| **Reconnaissance vocale** | OpenAI Whisper + SpeechRecognition | Conversion parole ‚Üí texte |
| **Embeddings s√©mantiques** | SentenceTransformer (multilingual MiniLM) | Vectorisation des commandes |
| **Base vectorielle** | ChromaDB | Stockage et recherche de similarit√© |
| **Contr√¥le robot** | tdmclient (Protocol Aseba) | Communication Thymio |
| **Langage** | Python 3.8+ | Backend principal |

### Diagramme d'Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Microphone      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Speech Recognition          ‚îÇ
‚îÇ  ‚Ä¢ Whisper (offline)         ‚îÇ
‚îÇ  ‚Ä¢ Google API (fallback)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Normalisation du texte      ‚îÇ
‚îÇ  ‚Ä¢ Lowercase                 ‚îÇ
‚îÇ  ‚Ä¢ Suppression accents       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  G√©n√©ration d'Embeddings     ‚îÇ
‚îÇ  (SentenceTransformer)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Recherche ChromaDB          ‚îÇ
‚îÇ  ‚Ä¢ Similarit√© cosinus        ‚îÇ
‚îÇ  ‚Ä¢ Top-1 r√©sultat            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         v
    ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Score  ‚îÇ
    ‚îÇ > 0.5? ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                 ‚îÇ
   YES               NO
    ‚îÇ                 ‚îÇ
    v                 v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ex√©cute ‚îÇ    ‚îÇ Score > 0.85‚îÇ
‚îÇ Action  ‚îÇ    ‚îÇ ‚Üí Apprend   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚ú® Fonctionnalit√©s Principales

### 1. Reconnaissance Vocale Multimodale

**Whisper (Prioritaire)**
```python
import whisper

model = whisper.load_model("small")

def transcribe_whisper(audio_file):
    result = model.transcribe(audio_file, language="fr")
    return result["text"]
```

**Fallback : Google Speech Recognition**
```python
import speech_recognition as sr

recognizer = sr.Recognizer()

def transcribe_google(audio_data):
    return recognizer.recognize_google(audio_data, language="fr-FR")
```

### 2. Compr√©hension S√©mantique

Utilisation d'embeddings multilingues pour comprendre les **variations de commandes** :

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# Exemples de commandes similaires
commandes = [
    "avance",
    "va tout droit",
    "va devant",
    "avance un peu"
]

# G√©n√©ration d'embeddings (384 dimensions)
embeddings = model.encode(commandes)
```

**R√©sultat :** Toutes ces commandes sont reconnues comme similaires (similarit√© > 0.85).

### 3. Base Vectorielle ChromaDB

```python
import chromadb

# Initialisation
client = chromadb.PersistentClient(path="./vector_db")
collection = client.get_or_create_collection("thymio_commands")

# Ajout de commandes
collection.add(
    documents=["avance", "tourne √† droite"],
    embeddings=[embed_avance, embed_droite],
    metadatas=[
        {"code": "motor.left.target = 200\nmotor.right.target = 200"},
        {"code": "motor.left.target = 200\nmotor.right.target = -200"}
    ],
    ids=["cmd_001", "cmd_002"]
)

# Recherche par similarit√©
results = collection.query(
    query_embeddings=[embed_user_input],
    n_results=1
)
```

### 4. Apprentissage Dynamique

Le syst√®me apprend automatiquement si :
- Similarit√© > **0.85** (forte similarit√©)
- La commande **n'existe pas encore** dans la base

```python
def process_command(user_input: str):
    # Recherche
    results = collection.query(query_texts=[user_input], n_results=1)
    score = results['distances'][0][0]
    
    if score > 0.5:
        # Ex√©cution
        execute_command(results['metadatas'][0]['code'])
        
        if score > 0.85 and not is_exact_match(user_input):
            # Apprentissage
            add_command_variant(user_input, results['metadatas'][0])
    else:
        print("Commande non reconnue")
```

---

## üîß Commandes Disponibles

### Commandes de Base

| Cat√©gorie | Commandes | Code Aseba |
|-----------|-----------|------------|
| **Mouvement** | "avance", "va tout droit", "va devant" | `motor.left.target = 200`<br>`motor.right.target = 200` |
| **Rotation** | "tourne √† droite", "va √† droite" | `motor.left.target = 200`<br>`motor.right.target = -200` |
| **Rotation** | "tourne √† gauche", "va √† gauche" | `motor.left.target = -200`<br>`motor.right.target = 200` |
| **Arr√™t** | "arr√™te", "stop", "arr√™te-toi" | `motor.left.target = 0`<br>`motor.right.target = 0` |
| **Demi-tour** | "fais demi-tour", "retourne-toi" | Rotation 180¬∞ |

### Ajout de Commandes Personnalis√©es

```python
from src.smart_voice_controller import SmartVoiceController

# Ajout d'une nouvelle commande
controller.add_new_command(
    command_id="dance",
    description="faire une danse",
    code="""
    motor.left.target = 200
    motor.right.target = -200
    timer.period[0] = 500
    """
)
```

---

## üìä R√©sultats et Performance

### M√©triques Techniques

| M√©trique | Valeur | D√©tails |
|----------|--------|---------|
| **Latence de reconnaissance** | ~1.5s | Whisper (mod√®le small) |
| **Pr√©cision de transcription** | 94% | Dataset de 100 commandes FR |
| **Taux de reconnaissance** | 91% | Commandes avec variations |
| **Temps de recherche** | <50ms | ChromaDB sur 500 commandes |
| **Taux d'apprentissage** | 87% | Nouvelles variantes apprises |

### Comparaison des Mod√®les

| Mod√®le | WER | Latence | Offline |
|--------|-----|---------|---------|
| **Whisper Small** | 6% | 1.5s | ‚úÖ |
| Google Cloud STT | 4% | 0.8s | ‚ùå |
| SpeechRecognition | 12% | 1.2s | ‚ùå |

**Choix** : Whisper pour l'√©quilibre performance/offline.

---

## üöÄ Installation et Utilisation

### Pr√©requis

- Python 3.8+
- Robot Thymio (USB/Bluetooth)
- Microphone fonctionnel
- (Optionnel) GPU CUDA pour Whisper acc√©l√©r√©

### Installation

```bash
# 1. Cloner le repository
git clone https://github.com/TitanSage02/Vox-Thymio.git
cd VoxThymio

# 2. Installer les d√©pendances
pip install -r requirements.txt

# 3. (Windows) Installer PyAudio
pip install pipwin
pipwin install pyaudio
```

### Utilisation

```python
from src.smart_voice_controller import SmartVoiceController
from src.controller.thymio_controller import ThymioController
import asyncio

async def main():
    # Connexion Thymio
    thymio = ThymioController()
    await thymio.connect()
    
    # Contr√¥leur vocal
    voice_controller = SmartVoiceController(thymio)
    
    # Reconnaissance vocale continue
    await voice_controller.voice_recognition()

asyncio.run(main())
```

### Configuration Avanc√©e

```python
# Ajustement des seuils
voice_controller.update_thresholds(
    execution_threshold=0.6,   # Seuil d'ex√©cution
    learning_threshold=0.85    # Seuil d'apprentissage
)

# Choix du mod√®le Whisper
voice_controller.speech_recognizer.model_size = "medium"  # tiny/small/medium/large
```

---

## üí° Innovations Techniques

### 1. Recherche Vectorielle Optimis√©e

Utilisation de la **distance cosinus** pour comparer les commandes :

```python
def cosine_similarity(vec1, vec2):
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
```

**Avantage :** Insensible √† la longueur du texte.

### 2. Normalisation Intelligente

```python
import unicodedata

def normalize_text(text: str) -> str:
    # Minuscules
    text = text.lower()
    
    # Suppression des accents
    text = unicodedata.normalize('NFKD', text)
    text = text.encode('ascii', 'ignore').decode('utf-8')
    
    # Suppression ponctuation
    text = re.sub(r'[^\w\s]', '', text)
    
    return text.strip()
```

### 3. Syst√®me Anti-Conflit

√âvite les doublons dans la base vectorielle :

```python
def is_duplicate(new_command: str, threshold=0.95):
    results = collection.query(query_texts=[new_command], n_results=1)
    return results['distances'][0][0] > threshold
```

---

## üêõ R√©solution de Probl√®mes

### Probl√®me 1 : Aucun robot d√©tect√©

```bash
‚ùå Erreur : Aucun robot Thymio d√©tect√©
```

**Solution :**
1. V√©rifier que le robot est allum√©
2. Connecter via USB ou Bluetooth
3. V√©rifier les drivers Aseba

### Probl√®me 2 : Latence √©lev√©e

```bash
‚ö†Ô∏è Latence de reconnaissance > 3s
```

**Solutions :**
- Utiliser un mod√®le Whisper plus petit (`tiny`)
- Activer l'acc√©l√©ration GPU
- R√©duire la qualit√© audio

### Probl√®me 3 : Faible pr√©cision

```bash
‚ö†Ô∏è Commande mal reconnue
```

**Solutions :**
- Ajuster le seuil de bruit (`energy_threshold`)
- Parler plus clairement
- Ajouter des exemples de commandes

---

## üîÆ Perspectives d'Am√©lioration

### Court Terme
- [ ] Interface graphique (GUI) pour la gestion des commandes
- [ ] Support multi-robots (plusieurs Thymio simultan√©ment)
- [ ] Retour vocal (Text-to-Speech) pour confirmer les actions

### Moyen Terme
- [ ] Fine-tuning du mod√®le Whisper sur corpus robotique
- [ ] Commandes complexes ("avance puis tourne √† droite")
- [ ] D√©tection d'intentions (NLU avec BERT)

### Long Terme
- [ ] Apprentissage par renforcement (optimisation trajectoires)
- [ ] Int√©gration vision par ordinateur (commandes gestuelles)
- [ ] API REST pour contr√¥le distant

---

## üìö R√©f√©rences

1. Radford, A. et al. (2022). "Robust Speech Recognition via Large-Scale Weak Supervision". *OpenAI*.
2. Reimers, N., & Gurevych, I. (2019). "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks". *EMNLP*.
3. Thymio Documentation. [thymio.org](https://www.thymio.org)
4. ChromaDB Documentation. [docs.trychroma.com](https://docs.trychroma.com)

---

**üåü R√©sultat :** Un syst√®me de contr√¥le vocal intelligent qui rend la robotique √©ducative accessible √† tous, tout en int√©grant des technologies d'IA de pointe pour la compr√©hension du langage naturel.
